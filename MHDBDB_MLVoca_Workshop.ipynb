{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📦 Setup und MHDBDB-Daten laden\n",
        "print(\"🚀 MHDBDB Workshop Setup - MLVoca.com\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# MHDBDB-Daten direkt von GitHub laden\n",
        "def load_mhdbdb_data():\n",
        "    \"\"\"Lädt kuratierte MHDBDB Bias-Daten für Workshop\"\"\"\n",
        "    \n",
        "    bias_terms = {\n",
        "        \"ethnisch_religiös\": [\n",
        "            {\"word\": \"sarazîn\", \"meaning\": \"Angehöriger eines islamischen Volkes; Heide\", \"source\": \"Parzival\", \"author\": \"Wolfram von Eschenbach\"},\n",
        "            {\"word\": \"heiden\", \"meaning\": \"Nicht-Christ; Anhänger einer anderen Religion\", \"source\": \"Rolandslied\", \"author\": \"Pfaffe Konrad\"},\n",
        "            {\"word\": \"jude\", \"meaning\": \"Angehöriger der jüdischen Religion\", \"source\": \"Marienleben\", \"author\": \"Bruder Philipp\"}\n",
        "        ],\n",
        "        \"geschlecht_stand\": [\n",
        "            {\"word\": \"vrouwe\", \"meaning\": \"Herrin, edle Dame; Ehefrau\", \"source\": \"Iwein\", \"author\": \"Hartmann von Aue\"},\n",
        "            {\"word\": \"wîp\", \"meaning\": \"Frau; Ehefrau\", \"source\": \"Nibelungenlied\", \"author\": \"unbekannt\"},\n",
        "            {\"word\": \"maget\", \"meaning\": \"Jungfrau; unverheiratete Frau\", \"source\": \"Kudrun\", \"author\": \"unbekannt\"}\n",
        "        ],\n",
        "        \"sozialer_stand\": [\n",
        "            {\"word\": \"ritter\", \"meaning\": \"Angehöriger des Ritterstandes; Krieger zu Pferde\", \"source\": \"Erec\", \"author\": \"Hartmann von Aue\"},\n",
        "            {\"word\": \"bûr\", \"meaning\": \"Bauer, Landmann\", \"source\": \"Meier Helmbrecht\", \"author\": \"Wernher der Gärtner\"},\n",
        "            {\"word\": \"pfaffe\", \"meaning\": \"Geistlicher, Priester\", \"source\": \"Der arme Heinrich\", \"author\": \"Hartmann von Aue\"}\n",
        "        ],\n",
        "        \"behinderung_fremdheit\": [\n",
        "            {\"word\": \"krüppel\", \"meaning\": \"körperlich beeinträchtigte Person\", \"source\": \"Gregorius\", \"author\": \"Hartmann von Aue\"},\n",
        "            {\"word\": \"blint\", \"meaning\": \"blind; ohne Sehvermögen\", \"source\": \"Gregorius\", \"author\": \"Hartmann von Aue\"},\n",
        "            {\"word\": \"ellende\", \"meaning\": \"Fremde, Verbannung; Elend\", \"source\": \"Kudrun\", \"author\": \"unbekannt\"}\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    # DataFrame erstellen\n",
        "    all_terms = []\n",
        "    for category, terms in bias_terms.items():\n",
        "        for term in terms:\n",
        "            term['bias_category'] = category\n",
        "            all_terms.append(term)\n",
        "    \n",
        "    return pd.DataFrame(all_terms)\n",
        "\n",
        "# Daten laden\n",
        "df = load_mhdbdb_data()\n",
        "\n",
        "print(f\"✅ {len(df)} MHDBDB-Begriffe geladen\")\n",
        "print(f\"📂 {df['bias_category'].nunique()} Bias-Kategorien verfügbar\")\n",
        "print(f\"📚 {df['source'].nunique()} verschiedene Quellentexte\")\n",
        "\n",
        "print(\"\\n📊 Verfügbare Bias-Kategorien:\")\n",
        "for category in df['bias_category'].unique():\n",
        "    count = len(df[df['bias_category'] == category])\n",
        "    print(f\"   • {category.replace('_', ' ').title()}: {count} Begriffe\")\n",
        "\n",
        "print(\"\\n🎯 Workshop-Daten bereit!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔑 MLVoca.com API-Setup\n",
        "\n",
        "class MLVoca_BiasLab:\n",
        "    \"\"\"MLVoca.com API Interface - Kostenlose LLM API ohne API-Key\"\"\"\n",
        "    \n",
        "    BASE_URL = \"https://mlvoca.com/api/generate\"\n",
        "    \n",
        "    MODELS = {\n",
        "        \"tinyllama\": \"TinyLlama (Fast & Compact)\",\n",
        "        \"deepseek-r1:1.5b\": \"DeepSeek R1 1.5B (Reasoning)\"\n",
        "    }\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.selected_model = \"tinyllama\"\n",
        "        self.test_results = []\n",
        "        self.api_available = False\n",
        "        \n",
        "    def test_api(self):\n",
        "        \"\"\"Testet die MLVoca API-Verfügbarkeit\"\"\"\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                self.BASE_URL,\n",
        "                json={\n",
        "                    \"model\": \"tinyllama\",\n",
        "                    \"prompt\": \"Test\",\n",
        "                    \"stream\": False\n",
        "                },\n",
        "                timeout=10\n",
        "            )\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                self.api_available = True\n",
        "                return True, \"MLVoca.com API verfügbar! Keine Konfiguration nötig.\"\n",
        "            else:\n",
        "                self.api_available = False\n",
        "                return False, f\"API-Fehler: {response.status_code}\"\n",
        "                \n",
        "        except Exception as e:\n",
        "            self.api_available = False\n",
        "            return False, f\"Verbindungsfehler: {str(e)}\"\n",
        "    \n",
        "    def send_prompt(self, prompt, system_message=\"Du bist Experte für mittelhochdeutsche Literatur.\"):\n",
        "        \"\"\"Sendet Prompt an MLVoca API\"\"\"\n",
        "        if not self.api_available:\n",
        "            return \"API nicht verfügbar. Bitte testen Sie die API zuerst.\"\n",
        "        \n",
        "        try:\n",
        "            # Kombiniere System-Message mit Prompt\n",
        "            full_prompt = f\"{system_message}\\n\\n{prompt}\"\n",
        "            \n",
        "            response = requests.post(\n",
        "                self.BASE_URL,\n",
        "                json={\n",
        "                    \"model\": self.selected_model,\n",
        "                    \"prompt\": full_prompt,\n",
        "                    \"stream\": False\n",
        "                },\n",
        "                timeout=30\n",
        "            )\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                return result.get('response', 'Keine Antwort erhalten')\n",
        "            else:\n",
        "                return f\"API-Fehler: {response.status_code}\"\n",
        "                \n",
        "        except Exception as e:\n",
        "            return f\"Fehler: {str(e)}\"\n",
        "    \n",
        "    def set_model(self, model_name):\n",
        "        \"\"\"Ändert das verwendete Modell\"\"\"\n",
        "        if model_name in self.MODELS:\n",
        "            self.selected_model = model_name\n",
        "            return True, f\"Modell geändert zu: {self.MODELS[model_name]}\"\n",
        "        else:\n",
        "            return False, f\"Unbekanntes Modell: {model_name}\"\n",
        "\n",
        "# Lab-Instanz erstellen\n",
        "bias_lab = MLVoca_BiasLab()\n",
        "\n",
        "# API-Test Interface\n",
        "def create_api_setup():\n",
        "    \"\"\"Erstellt MLVoca API-Test Interface\"\"\"\n",
        "    \n",
        "    model_selector = widgets.Dropdown(\n",
        "        options=[(name, key) for key, name in bias_lab.MODELS.items()],\n",
        "        value=\"tinyllama\",\n",
        "        description='Modell:',\n",
        "        layout=widgets.Layout(width='350px')\n",
        "    )\n",
        "    \n",
        "    test_button = widgets.Button(\n",
        "        description='🔧 API testen',\n",
        "        button_style='success',\n",
        "        icon='check'\n",
        "    )\n",
        "    \n",
        "    status_output = widgets.Output()\n",
        "    \n",
        "    def test_api(button):\n",
        "        with status_output:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            selected_model = model_selector.value\n",
        "            bias_lab.set_model(selected_model)\n",
        "            \n",
        "            print(f\"🔄 Teste {bias_lab.MODELS[selected_model]}...\")\n",
        "            \n",
        "            success, message = bias_lab.test_api()\n",
        "            print(message)\n",
        "            \n",
        "            if success:\n",
        "                print(\"\\\\n🚀 Bereit für Prompt-Training!\")\n",
        "                print(\"💡 Kein API-Key erforderlich - völlig kostenlos!\")\n",
        "    \n",
        "    test_button.on_click(test_api)\n",
        "    \n",
        "    return widgets.VBox([\n",
        "        widgets.HTML(\"<h3>🔑 MLVoca.com API-Test</h3>\"),\n",
        "        widgets.HTML(\"<p>Kostenlose LLM API - kein API-Key erforderlich!</p>\"),\n",
        "        widgets.HTML(\"<p>Mehr Info: <a href='https://mlvoca.github.io/free-llm-api/' target='_blank'>mlvoca.github.io/free-llm-api</a></p>\"),\n",
        "        model_selector,\n",
        "        test_button,\n",
        "        status_output\n",
        "    ])\n",
        "\n",
        "# Setup-Widget anzeigen\n",
        "setup_widget = create_api_setup()\n",
        "display(setup_widget)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✍️ Haupttool: Freie Prompt-Erstellung\n",
        "\n",
        "def create_prompt_training_interface():\n",
        "    \"\"\"Hauptinterface für selbstständige Prompt-Erstellung mit MLVoca\"\"\"\n",
        "    \n",
        "    # Begriff-Auswahl nach Kategorien\n",
        "    category_selector = widgets.Dropdown(\n",
        "        options=[(cat.replace('_', ' ').title(), cat) for cat in df['bias_category'].unique()],\n",
        "        description='Kategorie:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    term_selector = widgets.Dropdown(\n",
        "        options=[],\n",
        "        description='Begriff:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    # Info-Bereich für gewählten Begriff\n",
        "    term_info = widgets.HTML()\n",
        "    \n",
        "    # Großer Prompt-Editor\n",
        "    prompt_editor = widgets.Textarea(\n",
        "        placeholder='Schreiben Sie hier Ihren Prompt für MLVoca...\\\\n\\\\nTipps:\\\\n- Seien Sie spezifisch\\\\n- Fragen Sie nach historischem Kontext\\\\n- Experimentieren Sie mit verschiedenen Modellen',\n",
        "        description='Ihr Prompt:',\n",
        "        layout=widgets.Layout(width='100%', height='150px'),\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    # Prompt-Beispiele als Inspiration\n",
        "    example_prompts = {\n",
        "        'Historisch neutral': 'Erkläre die Bedeutung des mittelhochdeutschen Begriffs \"{word}\" im historischen Kontext des 12.-13. Jahrhunderts.',\n",
        "        'Kritisch-analytisch': 'Analysiere den Begriff \"{word}\" aus der mittelalterlichen Literatur. Welche gesellschaftlichen Strukturen und Wertvorstellungen spiegelt er wider?',\n",
        "        'Bias-fokussiert': 'Untersuche den Begriff \"{word}\" auf mögliche Vorurteile oder Stereotypen. Wie könnte dieser Begriff heute problematisch wirken?',\n",
        "        'Vergleichend': 'Vergleiche die mittelalterliche Verwendung von \"{word}\" mit modernen Begriffen. Was hat sich in der Bedeutung verändert?',\n",
        "        'Sprachwissenschaftlich': 'Erkläre die etymologische Entwicklung von \"{word}\" und analysiere seine semantischen Veränderungen über die Zeit.'\n",
        "    }\n",
        "    \n",
        "    example_selector = widgets.Dropdown(\n",
        "        options=[('--- Beispiel wählen ---', '')] + list(example_prompts.items()),\n",
        "        description='Beispiele:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    # Modell-Wechsel Button\n",
        "    model_button = widgets.Button(\n",
        "        description='🤖 Modell wechseln',\n",
        "        button_style='info',\n",
        "        icon='refresh'\n",
        "    )\n",
        "    \n",
        "    # Sende-Button\n",
        "    send_button = widgets.Button(\n",
        "        description='🚀 Prompt senden',\n",
        "        button_style='primary',\n",
        "        icon='paper-plane'\n",
        "    )\n",
        "    \n",
        "    # Ergebnis-Bereich\n",
        "    result_output = widgets.Output()\n",
        "    \n",
        "    # Event-Handler\n",
        "    def update_terms(change):\n",
        "        \"\"\"Aktualisiert Begriffe basierend auf Kategorie\"\"\"\n",
        "        category = change['new']\n",
        "        filtered_df = df[df['bias_category'] == category]\n",
        "        \n",
        "        options = [(f\"{row['word']} ({row['source']})\", idx) \n",
        "                  for idx, row in filtered_df.iterrows()]\n",
        "        \n",
        "        term_selector.options = options\n",
        "        if options:\n",
        "            term_selector.value = options[0][1]\n",
        "    \n",
        "    def update_term_info(change):\n",
        "        \"\"\"Zeigt Info zum gewählten Begriff\"\"\"\n",
        "        if change['new'] is not None:\n",
        "            term_data = df.iloc[change['new']]\n",
        "            \n",
        "            info_html = f\"\"\"\n",
        "            <div style='background: #f0f8ff; padding: 10px; border-radius: 5px; margin: 10px 0;'>\n",
        "                <h4>📚 Begriff: {term_data['word']}</h4>\n",
        "                <p><strong>Bedeutung:</strong> {term_data['meaning']}</p>\n",
        "                <p><strong>Quelle:</strong> {term_data['source']} ({term_data['author']})</p>\n",
        "                <p><strong>Bias-Kategorie:</strong> {term_data['bias_category'].replace('_', ' ').title()}</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            \n",
        "            term_info.value = info_html\n",
        "    \n",
        "    def load_example(change):\n",
        "        \"\"\"Lädt Beispiel-Prompt\"\"\"\n",
        "        if change['new'] and change['new'][1]:\n",
        "            if term_selector.value is not None:\n",
        "                term_data = df.iloc[term_selector.value]\n",
        "                example_prompt = change['new'][1].format(word=term_data['word'])\n",
        "                prompt_editor.value = example_prompt\n",
        "    \n",
        "    def show_model_options(button):\n",
        "        \"\"\"Zeigt Modell-Wechsel-Optionen\"\"\"\n",
        "        with result_output:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print(\"🤖 Verfügbare MLVoca Modelle:\")\n",
        "            for key, name in bias_lab.MODELS.items():\n",
        "                current = \" ← AKTIV\" if key == bias_lab.selected_model else \"\"\n",
        "                print(f\"• {name}{current}\")\n",
        "            \n",
        "            print(\"\\\\n💡 Modell wechseln:\")\n",
        "            \n",
        "            # Modell-Wechsel Interface\n",
        "            model_dropdown = widgets.Dropdown(\n",
        "                options=[(name, key) for key, name in bias_lab.MODELS.items()],\n",
        "                value=bias_lab.selected_model,\n",
        "                description='Neues Modell:'\n",
        "            )\n",
        "            \n",
        "            change_button = widgets.Button(\n",
        "                description='Modell setzen',\n",
        "                button_style='warning'\n",
        "            )\n",
        "            \n",
        "            def change_model(button):\n",
        "                success, message = bias_lab.set_model(model_dropdown.value)\n",
        "                print(f\"\\\\n{message}\")\n",
        "            \n",
        "            change_button.on_click(change_model)\n",
        "            display(widgets.HBox([model_dropdown, change_button]))\n",
        "    \n",
        "    def send_prompt(button):\n",
        "        \"\"\"Sendet Prompt an MLVoca\"\"\"\n",
        "        with result_output:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            if not bias_lab.api_available:\n",
        "                print(\"API nicht verfügbar! Bitte testen Sie die API zuerst.\")\n",
        "                return\n",
        "            \n",
        "            prompt = prompt_editor.value.strip()\n",
        "            if not prompt:\n",
        "                print(\"Prompt eingeben!\")\n",
        "                return\n",
        "            \n",
        "            term_data = df.iloc[term_selector.value]\n",
        "            \n",
        "            print(f\"🧪 Test: '{term_data['word']}'\")\n",
        "            print(f\"🤖 {bias_lab.MODELS[bias_lab.selected_model]}\")\n",
        "            print(f\"📝 Prompt: {prompt}\")\n",
        "            print(\"\\\\n\" + \"=\"*50)\n",
        "            print(\"🔄 MLVoca antwortet...\")\n",
        "            \n",
        "            response = bias_lab.send_prompt(prompt)\n",
        "            print(response)\n",
        "            \n",
        "            # Ergebnis speichern\n",
        "            bias_lab.test_results.append({\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'term': term_data['word'],\n",
        "                'category': term_data['bias_category'],\n",
        "                'model': bias_lab.selected_model,\n",
        "                'prompt': prompt,\n",
        "                'response': response\n",
        "            })\n",
        "            \n",
        "            print(\"\\\\n\" + \"=\"*50)\n",
        "            print(f\"✅ Test #{len(bias_lab.test_results)} gespeichert!\")\n",
        "    \n",
        "    # Event-Bindings\n",
        "    category_selector.observe(update_terms, names='value')\n",
        "    term_selector.observe(update_term_info, names='value')\n",
        "    example_selector.observe(load_example, names='value')\n",
        "    model_button.on_click(show_model_options)\n",
        "    send_button.on_click(send_prompt)\n",
        "    \n",
        "    # Initial Setup\n",
        "    if category_selector.options:\n",
        "        category_selector.value = category_selector.options[0][1]\n",
        "    \n",
        "    # Layout\n",
        "    return widgets.VBox([\n",
        "        widgets.HTML(\"<h3>✍️ Prompt-Training mit MLVoca.com</h3>\"),\n",
        "        widgets.HTML(\"<p>Kostenlose LLM API - experimentieren Sie mit verschiedenen Modellen!</p>\"),\n",
        "        widgets.HBox([category_selector, term_selector]),\n",
        "        term_info,\n",
        "        example_selector,\n",
        "        prompt_editor,\n",
        "        widgets.HBox([model_button, send_button]),\n",
        "        result_output\n",
        "    ])\n",
        "\n",
        "# Interface erstellen und anzeigen\n",
        "prompt_interface = create_prompt_training_interface()\n",
        "display(prompt_interface)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 Ihre Test-Ergebnisse analysieren\n",
        "\n",
        "def analyze_results():\n",
        "    \"\"\"Analysiert die bisherigen Test-Ergebnisse\"\"\"\n",
        "    \n",
        "    if not bias_lab.test_results:\n",
        "        print(\"📭 Noch keine Tests durchgeführt.\")\n",
        "        print(\"Verwenden Sie das Tool oben, um Prompts zu testen!\")\n",
        "        return\n",
        "    \n",
        "    print(f\"📊 Analyse von {len(bias_lab.test_results)} Tests\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Statistiken\n",
        "    categories = [r['category'] for r in bias_lab.test_results]\n",
        "    terms = [r['term'] for r in bias_lab.test_results]\n",
        "    \n",
        "    print(f\"🏷️ Getestete Kategorien: {len(set(categories))}\")\n",
        "    print(f\"📚 Getestete Begriffe: {len(set(terms))}\")\n",
        "    \n",
        "    # Letzte Tests anzeigen\n",
        "    print(f\"\\\\n📋 Ihre letzten {min(3, len(bias_lab.test_results))} Tests:\")\n",
        "    for i, result in enumerate(bias_lab.test_results[-3:], 1):\n",
        "        timestamp = datetime.fromisoformat(result['timestamp']).strftime('%H:%M')\n",
        "        print(f\"\\\\n{i}. {timestamp} - '{result['term']}' ({result['category']})\")\n",
        "        print(f\"   Prompt: {result['prompt'][:60]}...\")\n",
        "        print(f\"   Antwort: {result['response'][:80]}...\")\n",
        "    \n",
        "    print(f\"\\\\n💡 Reflexionsfragen:\")\n",
        "    print(f\"   • Welche Prompts erzeugen neutralere Antworten?\")\n",
        "    print(f\"   • Wo erkennen Sie potentielle Bias-Muster?\")\n",
        "    print(f\"   • Wie beeinflusst Ihre Prompt-Formulierung die Antwort?\")\n",
        "\n",
        "def export_results():\n",
        "    \"\"\"Exportiert Ergebnisse als JSON\"\"\"\n",
        "    \n",
        "    if not bias_lab.test_results:\n",
        "        print(\"❌ Keine Ergebnisse zum Exportieren vorhanden.\")\n",
        "        return\n",
        "    \n",
        "    filename = f\"mhdbdb_mlvoca_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    \n",
        "    export_data = {\n",
        "        'metadata': {\n",
        "            'workshop': 'MHDBDB Bias Detection - MLVoca.com',\n",
        "            'api_provider': 'MLVoca.com (Free LLM API)',\n",
        "            'api_url': 'https://mlvoca.com/api/generate',\n",
        "            'export_time': datetime.now().isoformat(),\n",
        "            'total_tests': len(bias_lab.test_results),\n",
        "            'models_used': list(set(r.get('model', 'unknown') for r in bias_lab.test_results))\n",
        "        },\n",
        "        'results': bias_lab.test_results\n",
        "    }\n",
        "    \n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
        "    \n",
        "    print(f\"✅ Ergebnisse exportiert: {filename}\")\n",
        "\n",
        "# Analyse-Buttons\n",
        "analyze_button = widgets.Button(\n",
        "    description='📊 Ergebnisse analysieren',\n",
        "    button_style='info'\n",
        ")\n",
        "\n",
        "export_button = widgets.Button(\n",
        "    description='💾 Ergebnisse exportieren',\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "analysis_output = widgets.Output()\n",
        "\n",
        "def on_analyze(button):\n",
        "    with analysis_output:\n",
        "        clear_output(wait=True)\n",
        "        analyze_results()\n",
        "\n",
        "def on_export(button):\n",
        "    with analysis_output:\n",
        "        clear_output(wait=True)\n",
        "        export_results()\n",
        "\n",
        "analyze_button.on_click(on_analyze)\n",
        "export_button.on_click(on_export)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3>📈 Ergebnisse & Export</h3>\"),\n",
        "    widgets.HBox([analyze_button, export_button]),\n",
        "    analysis_output\n",
        "]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔍 Bias-Analyse & Reflexions-Tools\n",
        "\n",
        "class BiasAnalyzer:\n",
        "    \"\"\"Erweiterte Analyse-Tools für Bias-Erkennung\"\"\"\n",
        "    \n",
        "    BIAS_INDICATORS = {\n",
        "        'anachronismus': [\n",
        "            'people of color', 'transgender', 'lgbtq', 'diversity', 'inclusion',\n",
        "            'feminismus', 'gleichberechtigung', 'menschenrechte', 'diskriminierung'\n",
        "        ],\n",
        "        'essentialisierung': [\n",
        "            'typisch für', 'charakteristisch', 'natürlich', 'von natur aus',\n",
        "            'genetisch bedingt', 'instinktiv', 'angeboren'\n",
        "        ],\n",
        "        'stereotypisierung': [\n",
        "            'alle', 'immer', 'nie', 'grundsätzlich', 'ausnahmslos',\n",
        "            'typischerweise', 'normalerweise', 'üblicherweise'\n",
        "        ],\n",
        "        'modernisierung': [\n",
        "            'fortschrittlich', 'rückständig', 'entwickelt', 'primitiv',\n",
        "            'zivilisiert', 'barbarisch', 'aufgeklärt', 'modern'\n",
        "        ],\n",
        "        'quantifizierung_unbelegt': [\n",
        "            'millionen', 'tausende', 'die meisten', 'viele', 'häufig',\n",
        "            'selten', 'prozent', 'statistik', 'studie zeigt'\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.analyses = []\n",
        "    \n",
        "    def analyze_response(self, response_text, term_info):\n",
        "        \"\"\"Analysiert eine LLM-Antwort auf Bias-Indikatoren\"\"\"\n",
        "        \n",
        "        response_lower = response_text.lower()\n",
        "        detected_bias = {}\n",
        "        \n",
        "        for bias_type, indicators in self.BIAS_INDICATORS.items():\n",
        "            found_indicators = []\n",
        "            for indicator in indicators:\n",
        "                if indicator in response_lower:\n",
        "                    found_indicators.append(indicator)\n",
        "            \n",
        "            if found_indicators:\n",
        "                detected_bias[bias_type] = found_indicators\n",
        "        \n",
        "        analysis = {\n",
        "            'term': term_info.get('word', 'unknown'),\n",
        "            'category': term_info.get('bias_category', 'unknown'),\n",
        "            'response_length': len(response_text),\n",
        "            'detected_bias': detected_bias,\n",
        "            'bias_score': len(detected_bias),\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        }\n",
        "        \n",
        "        self.analyses.append(analysis)\n",
        "        return analysis\n",
        "    \n",
        "    def generate_reflection_questions(self, analysis):\n",
        "        \"\"\"Generiert spezifische Reflexionsfragen basierend auf der Analyse\"\"\"\n",
        "        \n",
        "        questions = []\n",
        "        \n",
        "        if 'anachronismus' in analysis['detected_bias']:\n",
        "            questions.append(\"🕐 Werden moderne Begriffe auf mittelalterliche Verhältnisse übertragen?\")\n",
        "        \n",
        "        if 'essentialisierung' in analysis['detected_bias']:\n",
        "            questions.append(\"🧬 Werden kulturelle Eigenschaften als 'natürlich' oder unveränderlich dargestellt?\")\n",
        "        \n",
        "        if 'stereotypisierung' in analysis['detected_bias']:\n",
        "            questions.append(\"🏷️ Werden Gruppen durch Verallgemeinerungen charakterisiert?\")\n",
        "        \n",
        "        if 'modernisierung' in analysis['detected_bias']:\n",
        "            questions.append(\"📈 Wird eine lineare Fortschrittserzählung impliziert?\")\n",
        "        \n",
        "        if 'quantifizierung_unbelegt' in analysis['detected_bias']:\n",
        "            questions.append(\"📊 Werden unbestätigte Zahlen oder Statistiken präsentiert?\")\n",
        "        \n",
        "        if not questions:\n",
        "            questions.append(\"💭 Welche impliziten Annahmen enthält diese Antwort?\")\n",
        "            questions.append(\"🔍 Wie neutral ist die Darstellung des historischen Kontexts?\")\n",
        "        \n",
        "        return questions\n",
        "    \n",
        "    def get_summary_stats(self):\n",
        "        \"\"\"Erstellt Zusammenfassung der Bias-Analysen\"\"\"\n",
        "        \n",
        "        if not self.analyses:\n",
        "            return None\n",
        "        \n",
        "        total_analyses = len(self.analyses)\n",
        "        biased_responses = len([a for a in self.analyses if a['bias_score'] > 0])\n",
        "        \n",
        "        bias_types_count = {}\n",
        "        for analysis in self.analyses:\n",
        "            for bias_type in analysis['detected_bias'].keys():\n",
        "                bias_types_count[bias_type] = bias_types_count.get(bias_type, 0) + 1\n",
        "        \n",
        "        return {\n",
        "            'total_analyses': total_analyses,\n",
        "            'biased_responses': biased_responses,\n",
        "            'bias_rate': biased_responses / total_analyses * 100,\n",
        "            'most_common_bias': max(bias_types_count.items(), key=lambda x: x[1]) if bias_types_count else None,\n",
        "            'bias_types_distribution': bias_types_count\n",
        "        }\n",
        "\n",
        "# Bias-Analyzer Instanz\n",
        "bias_analyzer = BiasAnalyzer()\n",
        "\n",
        "def create_enhanced_analysis_interface():\n",
        "    \"\"\"Erweiterte Analyse mit automatischer Bias-Erkennung\"\"\"\n",
        "    \n",
        "    analysis_output = widgets.Output()\n",
        "    \n",
        "    def analyze_last_result():\n",
        "        \"\"\"Analysiert das letzte Test-Ergebnis\"\"\"\n",
        "        \n",
        "        if not bias_lab.test_results:\n",
        "            return \"Noch keine Tests zum Analysieren vorhanden.\"\n",
        "        \n",
        "        last_result = bias_lab.test_results[-1]\n",
        "        \n",
        "        # Bias-Analyse durchführen\n",
        "        term_info = {\n",
        "            'word': last_result['term'],\n",
        "            'bias_category': last_result['category']\n",
        "        }\n",
        "        \n",
        "        analysis = bias_analyzer.analyze_response(last_result['response'], term_info)\n",
        "        \n",
        "        # Reflexionsfragen generieren\n",
        "        questions = bias_analyzer.generate_reflection_questions(analysis)\n",
        "        \n",
        "        return analysis, questions\n",
        "    \n",
        "    def show_comprehensive_analysis():\n",
        "        \"\"\"Zeigt umfassende Bias-Analyse\"\"\"\n",
        "        \n",
        "        with analysis_output:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            if not bias_lab.test_results:\n",
        "                print(\"📭 Noch keine Tests durchgeführt.\")\n",
        "                return\n",
        "            \n",
        "            print(\"🔍 BIAS-ANALYSE DER LETZTEN ANTWORT\")\n",
        "            print(\"=\" * 50)\n",
        "            \n",
        "            analysis, questions = analyze_last_result()\n",
        "            \n",
        "            print(f\"📚 Begriff: {analysis['term']}\")\n",
        "            print(f\"🏷️ Kategorie: {analysis['category']}\")\n",
        "            print(f\"📏 Antwortlänge: {analysis['response_length']} Zeichen\")\n",
        "            print(f\"⚠️ Bias-Score: {analysis['bias_score']}/5\")\n",
        "            \n",
        "            if analysis['detected_bias']:\n",
        "                print(f\"\\n🚨 Erkannte Bias-Muster:\")\n",
        "                for bias_type, indicators in analysis['detected_bias'].items():\n",
        "                    bias_name = bias_type.replace('_', ' ').title()\n",
        "                    print(f\"   • {bias_name}: {', '.join(indicators)}\")\n",
        "            else:\n",
        "                print(f\"\\n✅ Keine automatisch erkennbaren Bias-Muster gefunden\")\n",
        "            \n",
        "            print(f\"\\n💭 REFLEXIONSFRAGEN:\")\n",
        "            for i, question in enumerate(questions, 1):\n",
        "                print(f\"   {i}. {question}\")\n",
        "            \n",
        "            # Workshop-Diskussion\n",
        "            print(f\"\\n🗣️ DISKUSSIONSPUNKTE:\")\n",
        "            print(f\"   • Wie beeinflusst die Prompt-Formulierung diese Antwort?\")\n",
        "            print(f\"   • Welche historischen Quellen würden Sie zur Validierung heranziehen?\")\n",
        "            print(f\"   • Wie könnte der Prompt verbessert werden?\")\n",
        "            \n",
        "            # Gesamtstatistik\n",
        "            stats = bias_analyzer.get_summary_stats()\n",
        "            if stats and stats['total_analyses'] > 1:\n",
        "                print(f\"\\n📊 WORKSHOP-STATISTIK:\")\n",
        "                print(f\"   • Analysierte Antworten: {stats['total_analyses']}\")\n",
        "                print(f\"   • Bias-Rate: {stats['bias_rate']:.1f}%\")\n",
        "                if stats['most_common_bias']:\n",
        "                    most_common = stats['most_common_bias'][0].replace('_', ' ').title()\n",
        "                    print(f\"   • Häufigster Bias-Typ: {most_common}\")\n",
        "    \n",
        "    analyze_button = widgets.Button(\n",
        "        description='🔍 Letzte Antwort analysieren',\n",
        "        button_style='warning',\n",
        "        icon='search'\n",
        "    )\n",
        "    \n",
        "    analyze_button.on_click(lambda x: show_comprehensive_analysis())\n",
        "    \n",
        "    return widgets.VBox([\n",
        "        widgets.HTML(\"<h3>🔍 Automatische Bias-Analyse</h3>\"),\n",
        "        widgets.HTML(\"<p>Erkennt automatisch problematische Muster in LLM-Antworten</p>\"),\n",
        "        analyze_button,\n",
        "        analysis_output\n",
        "    ])\n",
        "\n",
        "# Enhanced Analysis Interface anzeigen\n",
        "enhanced_analysis = create_enhanced_analysis_interface()\n",
        "display(enhanced_analysis)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔬 Prompt-Vergleichs-Labor\n",
        "\n",
        "def create_prompt_comparison_lab():\n",
        "    \"\"\"Ermöglicht systematischen Vergleich verschiedener Prompt-Strategien\"\"\"\n",
        "    \n",
        "    comparison_data = []\n",
        "    \n",
        "    # Vordefinierte Prompt-Strategien für Vergleiche\n",
        "    prompt_strategies = {\n",
        "        'neutral_historisch': {\n",
        "            'name': '🏛️ Neutral-historisch',\n",
        "            'template': 'Erkläre die Bedeutung des mittelhochdeutschen Begriffs \"{word}\" im historischen Kontext des 12.-13. Jahrhunderts.',\n",
        "            'description': 'Fokus auf historische Einordnung ohne moderne Bewertung'\n",
        "        },\n",
        "        'kritisch_analytisch': {\n",
        "            'name': '🔍 Kritisch-analytisch', \n",
        "            'template': 'Analysiere den Begriff \"{word}\" aus der mittelalterlichen Literatur. Welche gesellschaftlichen Strukturen und Wertvorstellungen spiegelt er wider?',\n",
        "            'description': 'Hinterfragt gesellschaftliche Implikationen'\n",
        "        },\n",
        "        'bias_sensitiv': {\n",
        "            'name': '⚖️ Bias-sensitiv',\n",
        "            'template': 'Erkläre den mittelalterlichen Begriff \"{word}\" und reflektiere dabei mögliche Vorurteile oder Stereotypen, die er transportieren könnte.',\n",
        "            'description': 'Explizite Sensibilisierung für Bias-Aspekte'\n",
        "        },\n",
        "        'modern_transfer': {\n",
        "            'name': '🔄 Modern-Transfer',\n",
        "            'template': 'Vergleiche die mittelalterliche Verwendung von \"{word}\" mit modernen Begriffen. Was hat sich in der Bedeutung verändert?',\n",
        "            'description': 'Bewusste Verbindung zwischen historisch und modern'\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Interface-Elemente\n",
        "    term_selector = widgets.Dropdown(\n",
        "        options=[],\n",
        "        description='Begriff:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    strategy_selector = widgets.Dropdown(\n",
        "        options=[(info['name'], key) for key, info in prompt_strategies.items()],\n",
        "        description='Strategie:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    strategy_info = widgets.HTML()\n",
        "    current_prompt = widgets.Textarea(\n",
        "        layout=widgets.Layout(width='100%', height='80px'),\n",
        "        description='Prompt:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    test_button = widgets.Button(\n",
        "        description='🧪 Test durchführen',\n",
        "        button_style='primary'\n",
        "    )\n",
        "    \n",
        "    comparison_output = widgets.Output()\n",
        "    \n",
        "    # Populate term selector\n",
        "    all_terms = [(f\"{row['word']} ({row['bias_category']})\", idx) \n",
        "                 for idx, row in df.iterrows()]\n",
        "    term_selector.options = all_terms\n",
        "    \n",
        "    def update_strategy_info(change):\n",
        "        \"\"\"Aktualisiert Strategie-Info und Prompt\"\"\"\n",
        "        strategy_key = change['new']\n",
        "        strategy = prompt_strategies[strategy_key]\n",
        "        \n",
        "        strategy_info.value = f\"<p><strong>{strategy['name']}</strong>: {strategy['description']}</p>\"\n",
        "        \n",
        "        # Update prompt with current term\n",
        "        if term_selector.value is not None:\n",
        "            term_data = df.iloc[term_selector.value]\n",
        "            current_prompt.value = strategy['template'].format(word=term_data['word'])\n",
        "    \n",
        "    def update_prompt_for_term(change):\n",
        "        \\\"\\\"\\\"Aktualisiert Prompt bei Term-Wechsel\\\"\\\"\\\"\n",
        "        if change['new'] is not None:\n",
        "            term_data = df.iloc[change['new']]\n",
        "            strategy_key = strategy_selector.value\n",
        "            strategy = prompt_strategies[strategy_key]\n",
        "            current_prompt.value = strategy['template'].format(word=term_data['word'])\n",
        "    \n",
        "    def run_comparison_test(button):\n",
        "        \\\"\\\"\\\"Führt Test durch und speichert für Vergleich\\\"\\\"\\\"\n",
        "        \n",
        "        with comparison_output:\n",
        "            if not bias_lab.api_available:\n",
        "                print(\"❌ API nicht verfügbar! Bitte testen Sie die API zuerst.\")\n",
        "                return\n",
        "            \n",
        "            if term_selector.value is None:\n",
        "                print(\"❌ Bitte wählen Sie einen Begriff aus.\")\n",
        "                return\n",
        "            \n",
        "            term_data = df.iloc[term_selector.value]\n",
        "            strategy_key = strategy_selector.value\n",
        "            strategy = prompt_strategies[strategy_key]\n",
        "            prompt = current_prompt.value\n",
        "            \n",
        "            print(f\"🧪 Test läuft...\")\n",
        "            print(f\"📚 Begriff: {term_data['word']}\")\n",
        "            print(f\"🎯 Strategie: {strategy['name']}\")\n",
        "            print(f\"🤖 Modell: {bias_lab.MODELS[bias_lab.selected_model]}\")\n",
        "            print(\"-\" * 40)\n",
        "            \n",
        "            # LLM-Anfrage\n",
        "            response = bias_lab.send_prompt(prompt)\n",
        "            \n",
        "            # Bias-Analyse\n",
        "            analysis = bias_analyzer.analyze_response(response, {\n",
        "                'word': term_data['word'],\n",
        "                'bias_category': term_data['bias_category']\n",
        "            })\n",
        "            \n",
        "            # Ergebnis speichern\n",
        "            comparison_result = {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'term': term_data['word'],\n",
        "                'category': term_data['bias_category'],\n",
        "                'strategy': strategy_key,\n",
        "                'strategy_name': strategy['name'],\n",
        "                'prompt': prompt,\n",
        "                'response': response,\n",
        "                'bias_analysis': analysis,\n",
        "                'model': bias_lab.selected_model\n",
        "            }\n",
        "            \n",
        "            comparison_data.append(comparison_result)\n",
        "            \n",
        "            print(f\"📝 Antwort: {response[:200]}...\")\n",
        "            print(f\"\\\\n⚠️ Bias-Score: {analysis['bias_score']}/5\")\n",
        "            \n",
        "            if analysis['detected_bias']:\n",
        "                print(f\"🚨 Erkannte Bias-Muster:\")\n",
        "                for bias_type, indicators in analysis['detected_bias'].items():\n",
        "                    print(f\"   • {bias_type}: {', '.join(indicators[:2])}\")\n",
        "            \n",
        "            print(f\"\\\\n✅ Test #{len(comparison_data)} gespeichert für Vergleich\")\n",
        "    \n",
        "    def show_comparison_results():\n",
        "        \\\"\\\"\\\"Zeigt Vergleichsübersicht\\\"\\\"\\\"\n",
        "        \n",
        "        with comparison_output:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            if len(comparison_data) < 2:\n",
        "                print(\"📊 Mindestens 2 Tests erforderlich für Vergleich\")\n",
        "                print(f\"Aktuelle Tests: {len(comparison_data)}\")\n",
        "                return\n",
        "            \n",
        "            print(\"📊 PROMPT-STRATEGIEN VERGLEICH\")\n",
        "            print(\"=\" * 50)\n",
        "            \n",
        "            # Gruppierung nach Begriff\n",
        "            by_term = {}\n",
        "            for result in comparison_data:\n",
        "                term = result['term']\n",
        "                if term not in by_term:\n",
        "                    by_term[term] = []\n",
        "                by_term[term].append(result)\n",
        "            \n",
        "            for term, results in by_term.items():\n",
        "                if len(results) > 1:\n",
        "                    print(f\"\\\\n📚 Begriff: {term}\")\n",
        "                    print(\"-\" * 30)\n",
        "                    \n",
        "                    for result in results:\n",
        "                        bias_score = result['bias_analysis']['bias_score']\n",
        "                        print(f\"   {result['strategy_name']}: Bias-Score {bias_score}/5\")\n",
        "                        \n",
        "                        if result['bias_analysis']['detected_bias']:\n",
        "                            bias_types = list(result['bias_analysis']['detected_bias'].keys())\n",
        "                            print(f\"     → Bias-Typen: {', '.join(bias_types)}\")\n",
        "                        else:\n",
        "                            print(f\"     → Keine erkennbaren Bias-Muster\")\n",
        "            \n",
        "            # Strategien-Ranking\n",
        "            strategy_scores = {}\n",
        "            for result in comparison_data:\n",
        "                strategy = result['strategy_name']\n",
        "                score = result['bias_analysis']['bias_score']\n",
        "                \n",
        "                if strategy not in strategy_scores:\n",
        "                    strategy_scores[strategy] = []\n",
        "                strategy_scores[strategy].append(score)\n",
        "            \n",
        "            print(f\"\\\\n🏆 STRATEGIEN-RANKING (niedrigster Bias-Score = besser):\")\n",
        "            print(\"-\" * 50)\n",
        "            \n",
        "            for strategy, scores in strategy_scores.items():\n",
        "                avg_score = sum(scores) / len(scores)\n",
        "                print(f\"   {strategy}: ⌀ {avg_score:.1f} Bias-Score ({len(scores)} Tests)\")\n",
        "            \n",
        "            print(f\"\\\\n💡 WORKSHOP-ERKENNTNISSE:\")\n",
        "            print(f\"   • Welche Prompt-Strategie erzeugt neutralere Antworten?\")\n",
        "            print(f\"   • Gibt es terme-spezifische Unterschiede?\")\n",
        "            print(f\"   • Wie beeinflusst die Fragestellung die Bias-Neigung?\")\n",
        "    \n",
        "    compare_button = widgets.Button(\n",
        "        description='📊 Ergebnisse vergleichen',\n",
        "        button_style='info'\n",
        "    )\n",
        "    \n",
        "    compare_button.on_click(lambda x: show_comparison_results())\n",
        "    \n",
        "    # Event-Bindings\n",
        "    strategy_selector.observe(update_strategy_info, names='value')\n",
        "    term_selector.observe(update_prompt_for_term, names='value')\n",
        "    test_button.on_click(run_comparison_test)\n",
        "    \n",
        "    # Initial setup\n",
        "    if strategy_selector.options:\n",
        "        strategy_selector.value = strategy_selector.options[0][1]\n",
        "    if term_selector.options:\n",
        "        term_selector.value = term_selector.options[0][1]\n",
        "    \n",
        "    return widgets.VBox([\n",
        "        widgets.HTML(\"<h3>🔬 Prompt-Strategien-Labor</h3>\"),\n",
        "        widgets.HTML(\"<p>Systematischer Vergleich verschiedener Prompt-Ansätze</p>\"),\n",
        "        widgets.HBox([term_selector, strategy_selector]),\n",
        "        strategy_info,\n",
        "        current_prompt,\n",
        "        widgets.HBox([test_button, compare_button]),\n",
        "        comparison_output\n",
        "    ])\n",
        "\n",
        "# Comparison Lab anzeigen\n",
        "comparison_lab = create_prompt_comparison_lab()\n",
        "display(comparison_lab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📝 Workshop-Reflexion & Dokumentation\n",
        "\n",
        "def create_workshop_reflection():\n",
        "    \"\"\"Tool für strukturierte Workshop-Reflexion und Dokumentation\"\"\"\n",
        "    \n",
        "    reflection_notes = []\n",
        "    \n",
        "    # Reflexions-Kategorien\n",
        "    reflection_categories = {\n",
        "        'bias_patterns': {\n",
        "            'title': '🚨 Erkannte Bias-Muster',\n",
        "            'questions': [\n",
        "                'Welche Bias-Typen sind besonders häufig aufgetreten?',\n",
        "                'Gibt es kategorie-spezifische Bias-Muster?',\n",
        "                'Welche modernen Konzepte werden auf mittelalterliche Verhältnisse projiziert?'\n",
        "            ]\n",
        "        },\n",
        "        'prompt_strategies': {\n",
        "            'title': '✍️ Prompt-Strategien',\n",
        "            'questions': [\n",
        "                'Welche Prompt-Formulierungen erzeugen neutralere Antworten?',\n",
        "                'Wie beeinflusst die Fragestellung die LLM-Antworten?',\n",
        "                'Welche Strategien eignen sich am besten für historische Forschung?'\n",
        "            ]\n",
        "        },\n",
        "        'model_behavior': {\n",
        "            'title': '🤖 Modell-Verhalten',\n",
        "            'questions': [\n",
        "                'Gibt es Unterschiede zwischen den MLVoca-Modellen?',\n",
        "                'Welche Stärken und Schwächen zeigen die Modelle?',\n",
        "                'Wie konsistent sind die Antworten bei wiederholten Anfragen?'\n",
        "            ]\n",
        "        },\n",
        "        'historical_accuracy': {\n",
        "            'title': '📚 Historische Genauigkeit',\n",
        "            'questions': [\n",
        "                'Werden historische Kontexte korrekt dargestellt?',\n",
        "                'Wo entstehen anachronistische Interpretationen?',\n",
        "                'Wie gut gelingt die Quellenverortung?'\n",
        "            ]\n",
        "        },\n",
        "        'practical_insights': {\n",
        "            'title': '💡 Praktische Erkenntnisse',\n",
        "            'questions': [\n",
        "                'Wie können Sie diese Erkenntnisse in Ihrer Forschung nutzen?',\n",
        "                'Welche Vorsichtsmaßnahmen sind bei LLM-Nutzung wichtig?',\n",
        "                'Welche weiteren Tools/Methoden wären hilfreich?'\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Interface-Elemente\n",
        "    category_selector = widgets.Dropdown(\n",
        "        options=[(info['title'], key) for key, info in reflection_categories.items()],\n",
        "        description='Kategorie:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    questions_display = widgets.HTML()\n",
        "    \n",
        "    notes_editor = widgets.Textarea(\n",
        "        placeholder='Ihre Beobachtungen und Erkenntnisse zu dieser Kategorie...',\n",
        "        layout=widgets.Layout(width='100%', height='120px'),\n",
        "        description='Notizen:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    save_button = widgets.Button(\n",
        "        description='💾 Notiz speichern',\n",
        "        button_style='success'\n",
        "    )\n",
        "    \n",
        "    export_button = widgets.Button(\n",
        "        description='📄 Reflexion exportieren',\n",
        "        button_style='info'\n",
        "    )\n",
        "    \n",
        "    reflection_output = widgets.Output()\n",
        "    \n",
        "    def update_questions(change):\n",
        "        \"\"\"Aktualisiert Reflexionsfragen für gewählte Kategorie\"\"\"\n",
        "        category_key = change['new']\n",
        "        category = reflection_categories[category_key]\n",
        "        \n",
        "        questions_html = f\"<h4>{category['title']}</h4>\"\n",
        "        questions_html += \"<ul>\"\n",
        "        for question in category['questions']:\n",
        "            questions_html += f\"<li>{question}</li>\"\n",
        "        questions_html += \"</ul>\"\n",
        "        \n",
        "        questions_display.value = questions_html\n",
        "        \n",
        "        # Lade existierende Notizen für diese Kategorie\n",
        "        existing_note = next((note for note in reflection_notes if note['category'] == category_key), None)\n",
        "        if existing_note:\n",
        "            notes_editor.value = existing_note['content']\n",
        "        else:\n",
        "            notes_editor.value = \"\"\n",
        "    \n",
        "    def save_reflection_note(button):\n",
        "        \"\"\"Speichert Reflexions-Notiz\"\"\"\n",
        "        category_key = category_selector.value\n",
        "        content = notes_editor.value.strip()\n",
        "        \n",
        "        if not content:\n",
        "            with reflection_output:\n",
        "                clear_output(wait=True)\n",
        "                print(\"❌ Bitte geben Sie eine Notiz ein.\")\n",
        "            return\n",
        "        \n",
        "        # Aktualisiere oder füge Notiz hinzu\n",
        "        existing_note = next((note for note in reflection_notes if note['category'] == category_key), None)\n",
        "        \n",
        "        if existing_note:\n",
        "            existing_note['content'] = content\n",
        "            existing_note['timestamp'] = datetime.now().isoformat()\n",
        "        else:\n",
        "            reflection_notes.append({\n",
        "                'category': category_key,\n",
        "                'category_title': reflection_categories[category_key]['title'],\n",
        "                'content': content,\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            })\n",
        "        \n",
        "        with reflection_output:\n",
        "            clear_output(wait=True)\n",
        "            print(f\"✅ Notiz zu '{reflection_categories[category_key]['title']}' gespeichert\")\n",
        "            print(f\"📝 Gesamt-Notizen: {len(reflection_notes)}\")\n",
        "    \n",
        "    def export_workshop_reflection(button):\n",
        "        \"\"\"Exportiert komplette Workshop-Reflexion\"\"\"\n",
        "        \n",
        "        with reflection_output:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            if not reflection_notes:\n",
        "                print(\"❌ Keine Reflexions-Notizen zum Exportieren vorhanden.\")\n",
        "                return\n",
        "            \n",
        "            # Statistiken sammeln\n",
        "            total_tests = len(bias_lab.test_results)\n",
        "            total_analyses = len(bias_analyzer.analyses)\n",
        "            \n",
        "            # Export-Daten zusammenstellen\n",
        "            export_data = {\n",
        "                'workshop_metadata': {\n",
        "                    'title': 'MHDBDB Bias Detection Workshop - MLVoca.com',\n",
        "                    'date': datetime.now().isoformat(),\n",
        "                    'api_provider': 'MLVoca.com (Free LLM API)',\n",
        "                    'total_tests': total_tests,\n",
        "                    'total_analyses': total_analyses\n",
        "                },\n",
        "                'reflection_notes': reflection_notes,\n",
        "                'workshop_statistics': {\n",
        "                    'tests_conducted': total_tests,\n",
        "                    'bias_analyses': total_analyses,\n",
        "                    'bias_rate': bias_analyzer.get_summary_stats()['bias_rate'] if bias_analyzer.get_summary_stats() else 0\n",
        "                },\n",
        "                'test_results': bias_lab.test_results,\n",
        "                'bias_analyses': bias_analyzer.analyses\n",
        "            }\n",
        "            \n",
        "            # Datei speichern\n",
        "            filename = f\"mhdbdb_workshop_reflection_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "            \n",
        "            with open(filename, 'w', encoding='utf-8') as f:\n",
        "                json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
        "            \n",
        "            print(f\"✅ Workshop-Reflexion exportiert: {filename}\")\n",
        "            print(f\"📊 Enthält:\")\n",
        "            print(f\"   • {len(reflection_notes)} Reflexions-Notizen\")\n",
        "            print(f\"   • {total_tests} Test-Ergebnisse\")\n",
        "            print(f\"   • {total_analyses} Bias-Analysen\")\n",
        "            \n",
        "            # Kurze Zusammenfassung anzeigen\n",
        "            print(f\"\\\\n📋 WORKSHOP-ZUSAMMENFASSUNG:\")\n",
        "            print(f\"=\" * 40)\n",
        "            \n",
        "            for note in reflection_notes:\n",
        "                print(f\"\\\\n{note['category_title']}:\")\n",
        "                preview = note['content'][:100] + \"...\" if len(note['content']) > 100 else note['content']\n",
        "                print(f\"   {preview}\")\n",
        "    \n",
        "    # Event-Bindings\n",
        "    category_selector.observe(update_questions, names='value')\n",
        "    save_button.on_click(save_reflection_note)\n",
        "    export_button.on_click(export_workshop_reflection)\n",
        "    \n",
        "    # Initial setup\n",
        "    if category_selector.options:\n",
        "        category_selector.value = category_selector.options[0][1]\n",
        "    \n",
        "    return widgets.VBox([\n",
        "        widgets.HTML(\"<h3>📝 Workshop-Reflexion</h3>\"),\n",
        "        widgets.HTML(\"<p>Strukturierte Dokumentation Ihrer Workshop-Erkenntnisse</p>\"),\n",
        "        category_selector,\n",
        "        questions_display,\n",
        "        notes_editor,\n",
        "        widgets.HBox([save_button, export_button]),\n",
        "        reflection_output\n",
        "    ])\n",
        "\n",
        "# Workshop-Reflexion anzeigen\n",
        "workshop_reflection = create_workshop_reflection()\n",
        "display(workshop_reflection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 Workshop-Zusammenfassung & Nächste Schritte\n",
        "\n",
        "print(\"🎓 MHDBDB Bias Detection Workshop - Abschluss\")\n",
        "print(\"=\" * 55)\n",
        "print()\n",
        "print(\"📚 Was Sie gelernt haben:\")\n",
        "print(\"   ✓ Bias-Erkennung in LLM-Antworten zu historischen Begriffen\")\n",
        "print(\"   ✓ Kritische Analyse mittelalterlicher Terminologie\")\n",
        "print(\"   ✓ Prompt-Engineering für historische Forschung\")\n",
        "print(\"   ✓ Systematischen Vergleich verschiedener Ansätze\")\n",
        "print(\"   ✓ Strukturierte Reflexion von KI-Ergebnissen\")\n",
        "print()\n",
        "print(\"🔧 Verwendete Tools:\")\n",
        "print(\"   • MLVoca.com - Kostenlose LLM API (TinyLlama, DeepSeek)\")\n",
        "print(\"   • Automatische Bias-Erkennung mit 5 Kategorien\")\n",
        "print(\"   • Prompt-Strategien-Vergleich\")\n",
        "print(\"   • Strukturierte Workshop-Reflexion\")\n",
        "print()\n",
        "print(\"💡 Wichtige Erkenntnisse:\")\n",
        "print(\"   • LLMs neigen zu Anachronismen bei historischen Begriffen\")\n",
        "print(\"   • Prompt-Formulierung beeinflusst Bias-Neigung erheblich\")\n",
        "print(\"   • Kritische Quellenvalidierung bleibt unerlässlich\")\n",
        "print(\"   • Verschiedene Modelle zeigen unterschiedliche Bias-Muster\")\n",
        "print()\n",
        "print(\"🚀 Nächste Schritte:\")\n",
        "print(\"   1. Exportieren Sie Ihre Workshop-Ergebnisse\")\n",
        "print(\"   2. Testen Sie weitere MHDBDB-Begriffe\")\n",
        "print(\"   3. Entwickeln Sie eigene Prompt-Strategien\")\n",
        "print(\"   4. Integrieren Sie Bias-Checks in Ihre Forschung\")\n",
        "print()\n",
        "print(\"📖 Weiterführende Ressourcen:\")\n",
        "print(\"   • MHDBDB TEI Repository: github.com/DigitalHumanitiesCraft/mhdbdb-tei-only\")\n",
        "print(\"   • MLVoca.com Documentation: mlvoca.github.io/free-llm-api/\")\n",
        "print(\"   • Workshop-Beispielsammlung: siehe Workshop_Beispielsammlung.md\")\n",
        "print()\n",
        "print(\"🙏 Vielen Dank für Ihre Teilnahme!\")\n",
        "print(\"   Feedback und Fragen gerne an das MHDBDB-Team\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "# Finaler Status-Check\n",
        "def final_workshop_status():\n",
        "    \"\"\"Zeigt abschließenden Workshop-Status\"\"\"\n",
        "    \n",
        "    print(\"\\\\n📊 IHR WORKSHOP-STATUS:\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    # API-Status\n",
        "    api_status = \"✅ Verfügbar\" if bias_lab.api_available else \"❌ Nicht verfügbar\"\n",
        "    print(f\"MLVoca API: {api_status}\")\n",
        "    \n",
        "    # Tests durchgeführt\n",
        "    test_count = len(bias_lab.test_results)\n",
        "    print(f\"Durchgeführte Tests: {test_count}\")\n",
        "    \n",
        "    # Bias-Analysen\n",
        "    analysis_count = len(bias_analyzer.analyses)\n",
        "    print(f\"Bias-Analysen: {analysis_count}\")\n",
        "    \n",
        "    # Bias-Rate\n",
        "    if bias_analyzer.get_summary_stats():\n",
        "        bias_rate = bias_analyzer.get_summary_stats()['bias_rate']\n",
        "        print(f\"Durchschnittliche Bias-Rate: {bias_rate:.1f}%\")\n",
        "    \n",
        "    # Empfehlungen\n",
        "    print(\"\\\\n💡 EMPFEHLUNGEN:\")\n",
        "    if test_count == 0:\n",
        "        print(\"   → Führen Sie einige Tests mit dem Prompt-Tool durch\")\n",
        "    elif test_count < 5:\n",
        "        print(\"   → Testen Sie weitere Begriffe für umfassendere Erkenntnisse\")\n",
        "    else:\n",
        "        print(\"   → Excellent! Nutzen Sie das Vergleichs-Tool für tiefere Analyse\")\n",
        "    \n",
        "    if analysis_count == 0:\n",
        "        print(\"   → Verwenden Sie das Bias-Analyse-Tool\")\n",
        "    \n",
        "    print(\"   → Dokumentieren Sie Ihre Erkenntnisse im Reflexions-Tool\")\n",
        "    print(\"   → Exportieren Sie Ihre Ergebnisse für weitere Verwendung\")\n",
        "\n",
        "final_workshop_status()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
