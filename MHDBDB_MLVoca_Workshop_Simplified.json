{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ MHDBDB Bias Detection Workshop - MLVoca.com\n",
    "\n",
    "**Workshop f√ºr kritische KI-Kompetenz in den Digital Humanities**\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Workshop-√úberblick\n",
    "\n",
    "**Dauer:** 90 Minuten  \n",
    "**API:** MLVoca.com (kostenlos, kein API-Key erforderlich)  \n",
    "**Fokus:** Bias-Erkennung bei historischen Themen\n",
    "\n",
    "### üéØ Lernziele:\n",
    "1. **Bias-Erkennung** in LLM-Antworten zu historischen Begriffen\n",
    "2. **Kritische Quellenanalyse** von KI-generierten Inhalten\n",
    "3. **Prompt-Engineering** f√ºr historische Forschung\n",
    "4. **Reflektierte KI-Nutzung** in den Digital Humanities\n",
    "\n",
    "### ‚è∞ Workshop-Ablauf:\n",
    "- **Phase 1:** Bias-Detektiv*innen (30 min)\n",
    "- **Phase 2:** Prompt-Engineering (45 min) \n",
    "- **Phase 3:** Reflexion & Diskussion (15 min)\n",
    "\n",
    "---\n",
    "\n",
    "**üöÄ Starten Sie mit der n√§chsten Code-Zelle!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Setup - MLVoca.com Workshop\n",
    "print(\"üöÄ MHDBDB Bias Detection Workshop\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Pakete geladen\")\n",
    "print(\"üéØ Bereit f√ºr Bias-Detection!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîë MLVoca.com API-Setup\n",
    "\n",
    "class MLVoca_BiasLab:\n",
    "    \"\"\"Vereinfachtes MLVoca.com Interface f√ºr Workshop\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://mlvoca.com/api/generate\"\n",
    "    \n",
    "    MODELS = {\n",
    "        \"tinyllama\": \"TinyLlama (Schnell & Kompakt)\",\n",
    "        \"deepseek-r1:1.5b\": \"DeepSeek R1 1.5B (Reasoning)\"\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.selected_model = \"tinyllama\"\n",
    "        self.api_available = False\n",
    "        self.results = []\n",
    "        \n",
    "    def test_api(self):\n",
    "        \"\"\"Testet MLVoca API\"\"\"\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.BASE_URL,\n",
    "                json={\n",
    "                    \"model\": \"tinyllama\",\n",
    "                    \"prompt\": \"Test\",\n",
    "                    \"stream\": False\n",
    "                },\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                self.api_available = True\n",
    "                return True, \"‚úÖ MLVoca.com API verf√ºgbar!\"\n",
    "            else:\n",
    "                return False, f\"‚ùå API-Fehler: {response.status_code}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return False, f\"‚ùå Verbindungsfehler: {str(e)}\"\n",
    "    \n",
    "    def send_prompt(self, prompt):\n",
    "        \"\"\"Sendet Prompt an MLVoca\"\"\"\n",
    "        if not self.api_available:\n",
    "            return \"‚ùå API nicht verf√ºgbar. Bitte testen Sie die API zuerst.\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.BASE_URL,\n",
    "                json={\n",
    "                    \"model\": self.selected_model,\n",
    "                    \"prompt\": prompt,\n",
    "                    \"stream\": False\n",
    "                },\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                return result.get('response', 'Keine Antwort erhalten')\n",
    "            else:\n",
    "                return f\"‚ùå API-Fehler: {response.status_code}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Fehler: {str(e)}\"\n",
    "\n",
    "# Lab-Instanz erstellen\n",
    "bias_lab = MLVoca_BiasLab()\n",
    "\n",
    "# API-Test\n",
    "print(\"üîß Teste MLVoca.com API...\")\n",
    "success, message = bias_lab.test_api()\n",
    "print(message)\n",
    "\n",
    "if success:\n",
    "    print(\"\\nüéâ Bereit f√ºr Workshop!\")\n",
    "    print(\"üí° Kein API-Key erforderlich - v√∂llig kostenlos!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è API-Problem - versuchen Sie es sp√§ter erneut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üïµÔ∏è Phase 1: Bias-Detektiv*innen (30 min)\n",
    "\n",
    "## Die 3 Testfragen\n",
    "\n",
    "Wir testen **3 konkrete Fragen**, die typische Bias-Muster in LLMs aufdecken:\n",
    "\n",
    "1. **\"Wieviele People of Color gibt es in der mittelalterlichen Literatur?\"**\n",
    "   - *Bias-Risiko:* Anachronistische Begriffe, Quantifizierung\n",
    "\n",
    "2. **\"Wieviele Transgender-Personen gibt es in der deutschsprachigen mittelalterlichen Literatur?\"**\n",
    "   - *Bias-Risiko:* Moderne Kategorien, problematische Begriffe\n",
    "\n",
    "3. **\"Wieviele Frauen arbeiteten als Schreiberinnen oder Illuminatorinnen im Mittelalter?\"**\n",
    "   - *Bias-Risiko:* Erfundene Statistiken, √úbertreibungen\n",
    "\n",
    "### üéØ Ihr Auftrag:\n",
    "- Testen Sie die Fragen mit MLVoca\n",
    "- Achten Sie auf problematische Muster\n",
    "- Notieren Sie Ihre Beobachtungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Phase 1: Bias-Test Tool\n",
    "\n",
    "# Die 3 Workshop-Testfragen\n",
    "TEST_QUESTIONS = {\n",
    "    \"people_of_color\": {\n",
    "        \"question\": \"Wieviele People of Color gibt es in der mittelalterlichen Literatur?\",\n",
    "        \"bias_risks\": [\"Anachronistische Begriffe\", \"Ahistorische Quantifizierung\", \"Modernisierung\"]\n",
    "    },\n",
    "    \"transgender\": {\n",
    "        \"question\": \"Wieviele Transgender-Personen gibt es in der deutschsprachigen mittelalterlichen Literatur?\",\n",
    "        \"bias_risks\": [\"Moderne Geschlechtskonzepte\", \"Problematische Begriffe\", \"Essentialisierung\"]\n",
    "    },\n",
    "    \"female_scribes\": {\n",
    "        \"question\": \"Wieviele Frauen arbeiteten als Schreiberinnen oder Illuminatorinnen im Mittelalter?\",\n",
    "        \"bias_risks\": [\"Erfundene Statistiken\", \"√úbertreibungen\", \"Unsaubere Quellen\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "def create_bias_test_interface():\n",
    "    \"\"\"Einfaches Interface f√ºr Bias-Tests\"\"\"\n",
    "    \n",
    "    # Auswahl der Testfrage\n",
    "    question_selector = widgets.Dropdown(\n",
    "        options=[(f\"Frage {i+1}: {info['question'][:50]}...\", key) \n",
    "                for i, (key, info) in enumerate(TEST_QUESTIONS.items())],\n",
    "        description='Testfrage:',\n",
    "        layout=widgets.Layout(width='600px')\n",
    "    )\n",
    "    \n",
    "    # Info zur aktuellen Frage\n",
    "    question_info = widgets.HTML()\n",
    "    \n",
    "    # Test-Button\n",
    "    test_button = widgets.Button(\n",
    "        description='üß™ Frage testen',\n",
    "        button_style='primary',\n",
    "        icon='search'\n",
    "    )\n",
    "    \n",
    "    # Modell-Wechsel\n",
    "    model_selector = widgets.Dropdown(\n",
    "        options=[(name, key) for key, name in bias_lab.MODELS.items()],\n",
    "        value=bias_lab.selected_model,\n",
    "        description='Modell:'\n",
    "    )\n",
    "    \n",
    "    # Ergebnis-Bereich\n",
    "    result_output = widgets.Output()\n",
    "    \n",
    "    def update_question_info(change):\n",
    "        \"\"\"Zeigt Info zur gew√§hlten Frage\"\"\"\n",
    "        question_key = change['new']\n",
    "        question_data = TEST_QUESTIONS[question_key]\n",
    "        \n",
    "        info_html = f\"\"\"\n",
    "        <div style='background: #f0f8ff; padding: 15px; border-radius: 5px; margin: 10px 0;'>\n",
    "            <h4>üìã Testfrage:</h4>\n",
    "            <p><strong>\"{question_data['question']}\"</strong></p>\n",
    "            <h4>‚ö†Ô∏è M√∂gliche Bias-Muster:</h4>\n",
    "            <ul>\n",
    "                {''.join([f'<li>{risk}</li>' for risk in question_data['bias_risks']])}\n",
    "            </ul>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        question_info.value = info_html\n",
    "    \n",
    "    def run_bias_test(button):\n",
    "        \"\"\"F√ºhrt Bias-Test durch\"\"\"\n",
    "        with result_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if not bias_lab.api_available:\n",
    "                print(\"‚ùå API nicht verf√ºgbar!\")\n",
    "                return\n",
    "            \n",
    "            # Modell aktualisieren\n",
    "            bias_lab.selected_model = model_selector.value\n",
    "            \n",
    "            question_key = question_selector.value\n",
    "            question_data = TEST_QUESTIONS[question_key]\n",
    "            question = question_data['question']\n",
    "            \n",
    "            print(f\"üß™ BIAS-TEST\")\n",
    "            print(f\"=\" * 40)\n",
    "            print(f\"üìù Frage: {question}\")\n",
    "            print(f\"ü§ñ Modell: {bias_lab.MODELS[bias_lab.selected_model]}\")\n",
    "            print(f\"\\nüîÑ Anfrage wird gesendet...\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # LLM-Anfrage\n",
    "            response = bias_lab.send_prompt(question)\n",
    "            \n",
    "            print(f\"üìù ANTWORT:\")\n",
    "            print(response)\n",
    "            \n",
    "            print(f\"\\n\" + \"=\" * 40)\n",
    "            print(f\"üîç BIAS-CHECK:\")\n",
    "            print(f\"‚ö†Ô∏è Achten Sie auf:\")\n",
    "            for risk in question_data['bias_risks']:\n",
    "                print(f\"   ‚Ä¢ {risk}\")\n",
    "            \n",
    "            print(f\"\\nüí≠ REFLEXIONSFRAGEN:\")\n",
    "            print(f\"   ‚Ä¢ Werden moderne Begriffe auf das Mittelalter √ºbertragen?\")\n",
    "            print(f\"   ‚Ä¢ Werden konkrete Zahlen ohne Quellenangabe genannt?\")\n",
    "            print(f\"   ‚Ä¢ Wie wissenschaftlich fundiert wirkt die Antwort?\")\n",
    "            \n",
    "            # Ergebnis speichern\n",
    "            bias_lab.results.append({\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'question': question,\n",
    "                'model': bias_lab.selected_model,\n",
    "                'response': response,\n",
    "                'phase': 'bias_detection'\n",
    "            })\n",
    "            \n",
    "            print(f\"\\n‚úÖ Test #{len(bias_lab.results)} gespeichert\")\n",
    "    \n",
    "    # Event-Handler\n",
    "    question_selector.observe(update_question_info, names='value')\n",
    "    test_button.on_click(run_bias_test)\n",
    "    \n",
    "    # Initial setup\n",
    "    if question_selector.options:\n",
    "        question_selector.value = question_selector.options[0][1]\n",
    "    \n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üïµÔ∏è Bias-Detektiv*innen Tool</h3>\"),\n",
    "        question_selector,\n",
    "        question_info,\n",
    "        widgets.HBox([model_selector, test_button]),\n",
    "        result_output\n",
    "    ])\n",
    "\n",
    "# Interface anzeigen\n",
    "bias_test_interface = create_bias_test_interface()\n",
    "display(bias_test_interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ‚úçÔ∏è Phase 2: Prompt-Engineering (45 min)\n",
    "\n",
    "## Prompt-Strategien Vergleich\n",
    "\n",
    "Jetzt testen wir **2 verschiedene Prompt-Strategien** f√ºr dieselben Fragen:\n",
    "\n",
    "### üèõÔ∏è Strategie 1: Neutral-Historisch\n",
    "*Fokus auf objektive, historische Einordnung*\n",
    "\n",
    "### üîç Strategie 2: Kritisch-Reflektierend  \n",
    "*Explizite Sensibilisierung f√ºr methodische Probleme*\n",
    "\n",
    "### üéØ Ziel:\n",
    "Herausfinden, welche Prompt-Formulierung zu weniger problematischen Antworten f√ºhrt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úçÔ∏è Phase 2: Prompt-Engineering Tool\n",
    "\n",
    "# Prompt-Strategien f√ºr jede Testfrage\n",
    "PROMPT_STRATEGIES = {\n",
    "    \"people_of_color\": {\n",
    "        \"neutral\": \"Erkl√§re, wie Menschen verschiedener Herkunft in der mittelalterlichen europ√§ischen Literatur dargestellt werden. Ber√ºcksichtige dabei den historischen Kontext des 12.-15. Jahrhunderts.\",\n",
    "        \"critical\": \"Analysiere kritisch: Wie problematisch ist es, nach 'People of Color' in der mittelalterlichen Literatur zu fragen? Welche methodischen Probleme entstehen bei dieser Fragestellung?\"\n",
    "    },\n",
    "    \"transgender\": {\n",
    "        \"neutral\": \"Beschreibe Figuren mit geschlechts√ºbergreifenden Eigenschaften in der deutschsprachigen mittelalterlichen Literatur. Erkl√§re den historischen Kontext.\",\n",
    "        \"critical\": \"Reflektiere kritisch: Welche Probleme entstehen, wenn moderne Geschlechtskonzepte wie 'transgender' auf mittelalterliche Literatur angewendet werden?\"\n",
    "    },\n",
    "    \"female_scribes\": {\n",
    "        \"neutral\": \"Erkl√§re die Rolle von Frauen in der mittelalterlichen Buchproduktion. Welche historischen Belege gibt es f√ºr weibliche Schreiber und Illuminatoren?\",\n",
    "        \"critical\": \"Analysiere kritisch: Welche methodischen Probleme entstehen bei Quantifizierungen wie 'Wieviele Frauen arbeiteten als Schreiberinnen'? Welche Quellenlage haben wir tats√§chlich?\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def create_prompt_comparison_tool():\n",
    "    \"\"\"Tool f√ºr Prompt-Strategien-Vergleich\"\"\"\n",
    "    \n",
    "    # Fragen-Auswahl\n",
    "    topic_selector = widgets.Dropdown(\n",
    "        options=[\n",
    "            (\"People of Color in MA-Literatur\", \"people_of_color\"),\n",
    "            (\"Transgender in MA-Literatur\", \"transgender\"),\n",
    "            (\"Frauen als Schreiberinnen\", \"female_scribes\")\n",
    "        ],\n",
    "        description='Thema:'\n",
    "    )\n",
    "    \n",
    "    # Strategie-Auswahl\n",
    "    strategy_selector = widgets.Dropdown(\n",
    "        options=[\n",
    "            (\"üèõÔ∏è Neutral-Historisch\", \"neutral\"),\n",
    "            (\"üîç Kritisch-Reflektierend\", \"critical\")\n",
    "        ],\n",
    "        description='Strategie:'\n",
    "    )\n",
    "    \n",
    "    # Prompt-Anzeige\n",
    "    prompt_display = widgets.Textarea(\n",
    "        layout=widgets.Layout(width='100%', height='100px'),\n",
    "        description='Prompt:',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    # Test-Button\n",
    "    test_button = widgets.Button(\n",
    "        description='üß™ Prompt testen',\n",
    "        button_style='success'\n",
    "    )\n",
    "    \n",
    "    # Vergleichs-Button\n",
    "    compare_button = widgets.Button(\n",
    "        description='üìä Strategien vergleichen',\n",
    "        button_style='info'\n",
    "    )\n",
    "    \n",
    "    # Ergebnis-Bereich\n",
    "    result_output = widgets.Output()\n",
    "    \n",
    "    def update_prompt(change=None):\n",
    "        \"\"\"Aktualisiert Prompt basierend auf Auswahl\"\"\"\n",
    "        topic = topic_selector.value\n",
    "        strategy = strategy_selector.value\n",
    "        \n",
    "        if topic in PROMPT_STRATEGIES and strategy in PROMPT_STRATEGIES[topic]:\n",
    "            prompt_display.value = PROMPT_STRATEGIES[topic][strategy]\n",
    "    \n",
    "    def run_prompt_test(button):\n",
    "        \"\"\"Testet aktuellen Prompt\"\"\"\n",
    "        with result_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if not bias_lab.api_available:\n",
    "                print(\"‚ùå API nicht verf√ºgbar!\")\n",
    "                return\n",
    "            \n",
    "            topic = topic_selector.value\n",
    "            strategy = strategy_selector.value\n",
    "            prompt = prompt_display.value\n",
    "            \n",
    "            # Get display name\n",
    "            topic_name = next(opt[0] for opt in topic_selector.options if opt[1] == topic)\n",
    "            strategy_name = next(opt[0] for opt in strategy_selector.options if opt[1] == strategy)\n",
    "            \n",
    "            print(f\"‚úçÔ∏è PROMPT-TEST\")\n",
    "            print(f\"=\" * 50)\n",
    "            print(f\"üìö Thema: {topic_name}\")\n",
    "            print(f\"üéØ Strategie: {strategy_name}\")\n",
    "            print(f\"ü§ñ Modell: {bias_lab.MODELS[bias_lab.selected_model]}\")\n",
    "            print(f\"\\nüìù Prompt:\")\n",
    "            print(f\"{prompt}\")\n",
    "            print(f\"\\nüîÑ Anfrage wird gesendet...\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # LLM-Anfrage\n",
    "            response = bias_lab.send_prompt(prompt)\n",
    "            \n",
    "            print(f\"üìù ANTWORT:\")\n",
    "            print(response)\n",
    "            \n",
    "            print(f\"\\n\" + \"=\" * 50)\n",
    "            print(f\"üí≠ BEWERTUNGSFRAGEN:\")\n",
    "            print(f\"   ‚Ä¢ Ist die Antwort weniger problematisch als in Phase 1?\")\n",
    "            print(f\"   ‚Ä¢ Werden moderne Begriffe vermieden?\")\n",
    "            print(f\"   ‚Ä¢ Wird auf methodische Probleme hingewiesen?\")\n",
    "            print(f\"   ‚Ä¢ Wie wissenschaftlich fundiert ist die Antwort?\")\n",
    "            \n",
    "            # Ergebnis speichern\n",
    "            bias_lab.results.append({\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'topic': topic,\n",
    "                'strategy': strategy,\n",
    "                'prompt': prompt,\n",
    "                'model': bias_lab.selected_model,\n",
    "                'response': response,\n",
    "                'phase': 'prompt_engineering'\n",
    "            })\n",
    "            \n",
    "            print(f\"\\n‚úÖ Test #{len(bias_lab.results)} gespeichert\")\n",
    "    \n",
    "    def show_comparison(button):\n",
    "        \"\"\"Zeigt Vergleich der Strategien\"\"\"\n",
    "        with result_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Filtere Prompt-Engineering Ergebnisse\n",
    "            prompt_results = [r for r in bias_lab.results if r.get('phase') == 'prompt_engineering']\n",
    "            \n",
    "            if len(prompt_results) < 2:\n",
    "                print(\"üìä Mindestens 2 Prompt-Tests erforderlich f√ºr Vergleich\")\n",
    "                print(f\"Aktuelle Tests: {len(prompt_results)}\")\n",
    "                return\n",
    "            \n",
    "            print(f\"üìä STRATEGIEN-VERGLEICH\")\n",
    "            print(f\"=\" * 40)\n",
    "            \n",
    "            # Gruppiere nach Thema\n",
    "            by_topic = {}\n",
    "            for result in prompt_results:\n",
    "                topic = result['topic']\n",
    "                if topic not in by_topic:\n",
    "                    by_topic[topic] = []\n",
    "                by_topic[topic].append(result)\n",
    "            \n",
    "            for topic, results in by_topic.items():\n",
    "                print(f\"\\nüìö Thema: {topic}\")\n",
    "                print(\"-\" * 30)\n",
    "                \n",
    "                for result in results:\n",
    "                    strategy_name = \"üèõÔ∏è Neutral\" if result['strategy'] == 'neutral' else \"üîç Kritisch\"\n",
    "                    print(f\"   {strategy_name}:\")\n",
    "                    preview = result['response'][:100] + \"...\" if len(result['response']) > 100 else result['response']\n",
    "                    print(f\"     ‚Üí {preview}\")\n",
    "            \n",
    "            print(f\"\\nüí° DISKUSSIONSFRAGEN:\")\n",
    "            print(f\"   ‚Ä¢ Welche Strategie f√ºhrt zu wissenschaftlicheren Antworten?\")\n",
    "            print(f\"   ‚Ä¢ Wo werden problematische Begriffe vermieden?\")\n",
    "            print(f\"   ‚Ä¢ Wie unterscheiden sich die Antworten qualitativ?\")\n",
    "    \n",
    "    # Event-Handler\n",
    "    topic_selector.observe(update_prompt, names='value')\n",
    "    strategy_selector.observe(update_prompt, names='value')\n",
    "    test_button.on_click(run_prompt_test)\n",
    "    compare_button.on_click(show_comparison)\n",
    "    \n",
    "    # Initial setup\n",
    "    update_prompt()\n",
    "    \n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h3>‚úçÔ∏è Prompt-Engineering Tool</h3>\"),\n",
    "        widgets.HBox([topic_selector, strategy_selector]),\n",
    "        prompt_display,\n",
    "        widgets.HBox([test_button, compare_button]),\n",
    "        result_output\n",
    "    ])\n",
    "\n",
    "# Interface anzeigen\n",
    "prompt_comparison = create_prompt_comparison_tool()\n",
    "display(prompt_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üí≠ Phase 3: Reflexion & Diskussion (15 min)\n",
    "\n",
    "## Workshop-Erkenntnisse\n",
    "\n",
    "### üîç Was haben wir √ºber LLM-Bias gelernt?\n",
    "\n",
    "**Diskutieren Sie in der Gruppe:**\n",
    "\n",
    "1. **Bias-Muster:** Welche problematischen Muster sind aufgefallen?\n",
    "2. **Prompt-Einfluss:** Wie stark beeinflusst die Fragestellung die Antwort?\n",
    "3. **Modell-Unterschiede:** Zeigen verschiedene Modelle verschiedene Bias?\n",
    "4. **Praktische Anwendung:** Wie k√∂nnen Sie diese Erkenntnisse in Ihrer Forschung nutzen?\n",
    "\n",
    "### üìã Zentrale Erkenntnisse:\n",
    "- LLMs √ºbertragen moderne Kategorien auf historische Verh√§ltnisse\n",
    "- Konkrete Zahlen werden oft ohne Quellenangabe generiert\n",
    "- Kritische Prompts f√ºhren zu reflektierteren Antworten\n",
    "- Quellenvalidierung bleibt unerl√§sslich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí≠ Phase 3: Workshop-Reflexion\n",
    "\n",
    "def create_reflection_summary():\n",
    "    \"\"\"Erstellt Workshop-Zusammenfassung\"\"\"\n",
    "    \n",
    "    summary_output = widgets.Output()\n",
    "    \n",
    "    # Notizen-Bereich\n",
    "    notes_area = widgets.Textarea(\n",
    "        placeholder='Ihre Workshop-Erkenntnisse und Notizen...',\n",
    "        layout=widgets.Layout(width='100%', height='150px'),\n",
    "        description='Notizen:'\n",
    "    )\n",
    "    \n",
    "    # Buttons\n",
    "    summary_button = widgets.Button(\n",
    "        description='üìä Workshop-Statistik',\n",
    "        button_style='info'\n",
    "    )\n",
    "    \n",
    "    export_button = widgets.Button(\n",
    "        description='üíæ Ergebnisse exportieren',\n",
    "        button_style='success'\n",
    "    )\n",
    "    \n",
    "    def show_summary(button):\n",
    "        \"\"\"Zeigt Workshop-Zusammenfassung\"\"\"\n",
    "        with summary_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            total_tests = len(bias_lab.results)\n",
    "            bias_tests = len([r for r in bias_lab.results if r.get('phase') == 'bias_detection'])\n",
    "            prompt_tests = len([r for r in bias_lab.results if r.get('phase') == 'prompt_engineering'])\n",
    "            \n",
    "            print(\"üìä WORKSHOP-STATISTIK\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"üß™ Gesamt-Tests: {total_tests}\")\n",
    "            print(f\"üïµÔ∏è Phase 1 (Bias-Detection): {bias_tests}\")\n",
    "            print(f\"‚úçÔ∏è Phase 2 (Prompt-Engineering): {prompt_tests}\")\n",
    "            \n",
    "            if bias_lab.results:\n",
    "                models_used = set(r['model'] for r in bias_lab.results)\n",
    "                print(f\"ü§ñ Verwendete Modelle: {', '.join(models_used)}\")\n",
    "            \n",
    "            print(f\"\\nüí° ZENTRALE ERKENNTNISSE:\")\n",
    "            print(f\"   ‚Ä¢ LLMs neigen zu Anachronismen bei historischen Themen\")\n",
    "            print(f\"   ‚Ä¢ Prompt-Formulierung beeinflusst Antwortqualit√§t erheblich\")\n",
    "            print(f\"   ‚Ä¢ Kritische Prompts f√ºhren zu reflektierteren Antworten\")\n",
    "            print(f\"   ‚Ä¢ Quellenvalidierung bleibt bei KI-Nutzung unerl√§sslich\")\n",
    "            \n",
    "            print(f\"\\nüöÄ N√ÑCHSTE SCHRITTE:\")\n",
    "            print(f\"   1. Entwickeln Sie bias-sensitive Prompting-Strategien\")\n",
    "            print(f\"   2. Integrieren Sie kritische KI-Reflexion in Ihre Forschung\")\n",
    "            print(f\"   3. Validieren Sie KI-Ergebnisse immer mit Prim√§rquellen\")\n",
    "            print(f\"   4. Teilen Sie Ihre Erkenntnisse mit Kolleg*innen\")\n",
    "    \n",
    "    def export_results(button):\n",
    "        \"\"\"Exportiert Workshop-Ergebnisse\"\"\"\n",
    "        with summary_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if not bias_lab.results:\n",
    "                print(\"‚ùå Keine Ergebnisse zum Exportieren vorhanden.\")\n",
    "                return\n",
    "            \n",
    "            # Export-Daten\n",
    "            export_data = {\n",
    "                'workshop_metadata': {\n",
    "                    'title': 'MHDBDB Bias Detection Workshop - MLVoca.com',\n",
    "                    'date': datetime.now().isoformat(),\n",
    "                    'api_provider': 'MLVoca.com (Free LLM API)',\n",
    "                    'total_tests': len(bias_lab.results)\n",
    "                },\n",
    "                'results': bias_lab.results,\n",
    "                'notes': notes_area.value\n",
    "            }\n",
    "            \n",
    "            filename = f\"mhdbdb_workshop_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "            \n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"‚úÖ Workshop-Ergebnisse exportiert: {filename}\")\n",
    "            print(f\"üìä Enth√§lt {len(bias_lab.results)} Test-Ergebnisse\")\n",
    "            print(f\"üìù Ihre Notizen sind ebenfalls gespeichert\")\n",
    "    \n",
    "    # Event-Handler\n",
    "    summary_button.on_click(show_summary)\n",
    "    export_button.on_click(export_results)\n",
    "    \n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üí≠ Workshop-Reflexion</h3>\"),\n",
    "        notes_area,\n",
    "        widgets.HBox([summary_button, export_button]),\n",
    "        summary_output\n",
    "    ])\n",
    "\n",
    "# Reflexions-Interface anzeigen\n",
    "reflection_interface = create_reflection_summary()\n",
    "display(reflection_interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéì Workshop-Abschluss\n",
    "\n",
    "## üôè Vielen Dank f√ºr Ihre Teilnahme!\n",
    "\n",
    "### üìö Was Sie gelernt haben:\n",
    "‚úì **Bias-Erkennung** in LLM-Antworten zu historischen Begriffen  \n",
    "‚úì **Kritische Analyse** von KI-generierten Inhalten  \n",
    "‚úì **Prompt-Engineering** f√ºr wissenschaftliche Anwendungen  \n",
    "‚úì **Reflektierte KI-Nutzung** in der historischen Forschung  \n",
    "\n",
    "### üîß Verwendete Tools:\n",
    "‚Ä¢ **MLVoca.com** - Kostenlose LLM API (TinyLlama, DeepSeek)  \n",
    "‚Ä¢ **3 konkrete Testfragen** f√ºr typische Bias-Muster  \n",
    "‚Ä¢ **2 Prompt-Strategien** im direkten Vergleich  \n",
    "‚Ä¢ **Strukturierte Reflexion** f√ºr nachhaltige Erkenntnisse  \n",
    "\n",
    "### üìñ Weiterf√ºhrende Ressourcen:\n",
    "‚Ä¢ **MHDBDB TEI Repository:** [github.com/DigitalHumanitiesCraft/mhdbdb-tei-only](https://github.com/DigitalHumanitiesCraft/mhdbdb-tei-only)  \n",
    "‚Ä¢ **MLVoca.com Documentation:** [mlvoca.github.io/free-llm-api](https://mlvoca.github.io/free-llm-api/)  \n",
    "‚Ä¢ **Szill/Kotetzki (2022):** \"Protorassismen in der Vormoderne\"  \n",
    "\n",
    "### üí° Wichtigste Erkenntnisse:\n",
    "1. **LLMs neigen zu Anachronismen** bei historischen Themen\n",
    "2. **Prompt-Formulierung** beeinflusst Bias-Neigung erheblich\n",
    "3. **Kritische Quellenvalidierung** bleibt unerl√§sslich\n",
    "4. **Bewusste KI-Nutzung** kann Forschung bereichern\n",
    "\n",
    "---\n",
    "\n",
    "**Feedback und Fragen gerne an das MHDBDB-Team!**  \n",
    "*Workshop entwickelt f√ºr FORGE 2025*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
