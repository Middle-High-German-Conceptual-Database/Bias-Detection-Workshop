Bias Detection in der historischen Textanalyse
Prompting, Perspektiven und semantische Präzision in der AI-Readiness der MHDBDB
Zusammenfassung. In diesem 90-minütigen Workshop untersuchen die Teilnehmenden anhand konkreter Beispiele aus der Mittelhochdeutschen Begriffsdatenbank (MHDBDB), wie sich Verzerrungen in historischen Textkorpora identifizieren und kritisch analysieren lassen. Die MHDBDB ist eine semantisch annotierte Forschungsinfrastruktur, die aktuell für den Einsatz in AI-gestützten Analyseverfahren vorbereitet wird. Ziel ist es, historische Daten nicht nur zugänglich, sondern auch reflektiert und bias-bewusst nutzbar zu machen.
Im Zentrum des Workshops stehen zwei aufeinander aufbauende Aktivitäten: Zunächst schlüpfen die Teilnehmenden in die Rolle von Bias-Detektiv*innen und analysieren ausgewählte Begriffe aus der MHDBDB auf potenzielle Verzerrungen durch moderne Lesarten oder normdatenbasierte Kategorien. Anschließend experimentieren sie mit verschiedenen Prompting-Strategien für Large Language Models (LLMs) beispielsweise ChatGPT, Llama, Claude o.ä., um zu erproben, wie sich unterschiedliche Fragestellungen auf die AI-generierten Antworten auswirken – insbesondere im Hinblick auf stereotype Reproduktionen oder historische Unschärfen.
Der Workshop vermittelt praxisnahe Kompetenzen im Umgang mit semantischen Kategorien, Prompting und der Analyse von Bias. Er fördert damit die Entwicklung kritischer Datenkompetenz in den Digital Humanities. Nach dem Workshop sind die Teilnehmenden in der Lage, eigenständig ein Prompt-Template zu erstellen, das stereotype Muster im Output von LLMs berücksichtigt und gezielt reduziert. Zugleich leistet der Workshop einen Beitrag zur methodischen Weiterentwicklung bias-sensibler KI-Infrastrukturen in der historischen Forschung.
Schlagwörter: Bias-Erkennung, Prompt Engineering, Historische Textanalyse.


Bias Detection in der historischen Textanalyse: Prompting, Perspektiven und semantische Präzision in der AI-Readiness der MHDBDB
Mit dem verstärkten Einsatz generativer KI-Modelle in den Digital Humanities entstehen neue methodische Zugänge zur Analyse historischer Texte. Gleichzeitig treten grundlegende Herausforderungen zutage: etwa im Hinblick auf Modelltransparenz, semantische Repräsentation und den Umgang mit epistemischen Verzerrungen. Der Workshop Bias Detection in der historischen Textanalyse greift diese Herausforderungen exemplarisch anhand der Mittelhochdeutschen Begriffsdatenbank (MHDBDB) auf, einer der traditionsreichsten digitalen Forschungsinfrastrukturen für die historische Linguistik und Literaturwissenschaft im deutschsprachigen Raum.
Die MHDBDB vereint ein umfangreiches, semantisch annotiertes Korpus mit über zehn Millionen Tokens und mehreren Milliarden RDF-Tripeln. Seit 1972 wird sie kontinuierlich ausgebaut und bildet heute eine hybride Datenstruktur, in der korpusbasierte Analysen und normdatenverankerte Informationen – etwa aus der GND oder Wikidata – miteinander verschränkt sind. Durch diese Struktur bietet sie großes Potenzial für KI-gestützte Forschung, bringt jedoch zugleich Herausforderungen im Hinblick auf Repräsentationslücken, Bedeutungsverengungen und das Risiko stereotyper Reproduktionen mit sich.
Im Zentrum des Workshops steht daher die Frage, wie sich historische Bedeutungen jenseits moderner Standardisierungslogiken erkennen und analysieren lassen – und wie sich generative Sprachmodelle in solchen Kontexten reflektiert einsetzen lassen. Die Teilnehmenden arbeiten mit ausgewählten Begriffen aus der MHDBDB und analysieren deren semantische Struktur sowie mögliche Verzerrungen durch moderne Lesarten, Datenkategorien oder normierende Begriffsrahmen. Aufbauend auf dieser Analyse entwickeln sie eigene Prompts zur Befragung generativer Modelle wie beispielsweise ChatGPT, Claude oder ähnlichen. Mithilfe gezielter Variationen untersuchen sie, wie sich stereotype Zuschreibungen, historische Vereinfachungen oder semantische Verschiebungen im Modell-Output manifestieren und wie sich diese durch verändertes Prompting beeinflussen lassen.
Der Workshop gliedert sich in mehrere, aufeinander aufbauende Phasen: Nach einem kurzen Einstieg zur Begriffsklärung und Sensibilisierung werden in Kleingruppen historische Begriffe kontextualisiert, analysiert und kritisch reflektiert. Anschließend folgen interaktive Übungen im Bereich des Prompt Engineerings, bei denen die Gruppen unterschiedliche Fragestellungen formulieren, mit KI-Modellen experimentieren und die Resultate gemeinsam diskutieren. Den Abschluss bildet eine moderierte Austauschrunde, in der zentrale Beobachtungen zusammengetragen und weiterführende Ressourcen vorgestellt werden. Die einzelnen Module werden durch Arbeitsmaterialien, vorbereitete Interfaces und begleitende Leitfragen strukturiert, lassen aber ausreichend Raum für Anpassung an das Vorwissen und die Interessen der Teilnehmenden.
Grundlage der praktischen Übungen sind vorbereitete Daten und Werkzeuge aus dem aktuell beantragten FWF-Projekt AI-Ready Historical Texts: MHDBDB as a Bias-Aware Resource. Das Projekt verfolgt das Ziel, die MHDBDB zu einer FAIR-kompatiblen, semantisch differenzierten Infrastruktur für KI-gestützte Textanalyse weiterzuentwickeln. Dabei steht insbesondere die Frage im Fokus, wie historische Sprachdaten so modelliert werden können, dass sowohl algorithmische Auswertung als auch kritische Reflexion und semantische Tiefenschärfe gewährleistet bleiben.
Der Workshop richtet sich an ein DH-affines Publikum. Vorkenntnisse im Umgang mit KI sind nicht erforderlich; vielmehr zielt das Format auf eine niedrigschwellige, praxisnahe Auseinandersetzung mit den Chancen und Risiken generativer Modelle im Umgang mit historischen Sprachkorpora. Neben inhaltlicher Analyse und technischem Experimentieren steht der Austausch im Vordergrund: Der Workshop ist als kollaboratives Lernumfeld konzipiert, das klassische geisteswissenschaftliche Methoden mit aktuellen KI-Praktiken verbindet.
Ziel ist es, nicht nur technische Kompetenzen im Bereich Prompting und semantischer Analyse zu vermitteln, sondern auch ein geschärftes Bewusstsein für den bias-sensiblen Umgang mit historischen Daten zu entwickeln. Dabei werden sowohl problematische Repräsentationslogiken als auch Möglichkeiten zu deren produktiver Irritation thematisiert. Die Teilnehmenden verlassen den Workshop mit konkreten Erfahrungen, einem erweiterten methodischen Repertoire und einem kritisch-reflektierten Blick auf die Rolle von KI in der historischen Textanalyse.

Literatur: 

An, Jiafu, Difang Huang, Chen Lin, und Mingzhu Tai. 2025. „Measuring gender and racial biases in large language models: Intersectional evidence from automated resume evaluation". PNAS Nexus 4 (3): pgaf089. https://doi.org/10.1093/pnasnexus/pgaf089.
Bolukbasi, Tolga, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, und Adam T Kalai. 2016. „Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings". In Advances in Neural Information Processing Systems. Bd. 29. Curran Associates, Inc. https://proceedings.neurips.cc/paper_files/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html.
Borek, Luise, Karoline Döring, Nora Ketschik, und Katharina Zeppezauer-Wachauer. 2025. Schnittstelle Mediävistik. Kollaborationen Der Mittelalterforschung Im Digitalen Zeitalter. Bd. 1. Das Mittelalter. Perspektiven Mediävistischer Forschung?: Zeitschrift Des Mediävistikverbandes 30. Heidelberg: Heidelberg University Publishing.
D'Ignazio, Catherine, und Lauren F. Klein. 2020. Data feminism. <Strong> ideas series. Cambridge, Massachusetts: The MIT Press.
Hintersteiner, Julia, Michael Göggelmann, Alan van Beek, und Katharina Zeppezauer-Wachauer. 2024. „Von der Datenpflege zur Schnittstellenentwicklung: Eine Evaluation des Datenkolosses MHDBDB". https://doi.org/10.58079/12P9N.
Kotek, Hadas, Rikker Dockum, und David Q. Sun. 2023. „Gender bias and stereotypes in Large Language Models". arXiv. https://doi.org/10.48550/arXiv.2308.14921.
Risam, Roopika. 2019. „Beyond the Margins: Intersectionality and Digital Humanities". In Intersectionality in Digital Humanities, herausgegeben von Barbara Bordalejo und Roopika Risam, 13–34. Amsterdam University Press. https://doi.org/10.1017/9781641890519.003.
Turpin, Miles, Julian Michael, Ethan Perez, und Samuel R. Bowman. 2023. „Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting". arXiv. https://doi.org/10.48550/arXiv.2305.04388.
Varnum, Michael E. W., Nicolas Baumard, Mohammad Atari, und Kurt Gray. 2024. „Large Language Models Based on Historical Text Could Offer Informative Tools for Behavioral Science". Proceedings of the National Academy of Sciences 121 (42): e2407639121. https://doi.org/10.1073/pnas.2407639121.
Moshövel, Andrea. 2009. „‚Afrikanerinnen' in der mittelhochdeutschen Literatur?" In Vorschen, denken, wizzen. - Stuttgart?: Hirzel, 77–92.
Szill, Rike, und Maline Kotetzki. 2022. „Protorassismen in der Vormoderne. Ein Plädoyer für mehr Ungemütlichkeit in der mediävistischen Forschung und Lehre". Traverse: Zeitschrift für Geschichte = Revue d'histoire 29 (Vormoderne postkolonial? = Moyen âge postcolonial?): 121–37. 